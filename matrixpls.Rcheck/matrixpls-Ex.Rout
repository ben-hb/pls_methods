
R version 4.0.3 (2020-10-10) -- "Bunny-Wunnies Freak Out"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin17.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "matrixpls"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('matrixpls')

Attaching package: ‘matrixpls’

The following objects are masked from ‘package:stats’:

    ave, loadings

> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("GSCA")
> ### * GSCA
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: GSCA
> ### Title: Generalized structured component analysis (GSCA) weights
> ### Aliases: GSCA
> 
> ### ** Examples
> 
> if(!require(ASGSCA)){
+     print("This example requires the ASGSCA package from Bioconductor")
+ } else{
+ # Run the example from ASGSCA package using GSCA estimation
+ 
+ data(GenPhen)
+ W0 <- matrix(c(rep(1,2),rep(0,8),rep(1,2),rep(0,8),rep(1,3),rep(0,7),rep(1,2)),
+              nrow=8,ncol=4)
+ B0 <- matrix(c(rep(0,8),rep(1,2),rep(0,3),1,rep(0,2)),nrow=4,ncol=4)
+ 
+ # Set seed becayse ASGSCA uses random numbers as starting values 
+ set.seed(1)
+ 
+ GSCA.res <-GSCA(GenPhen,W0, B0,estim=TRUE,path.test=FALSE, 
+                  latent.names=c("Gene1","Gene2",
+                                 "Clinical pathway 1",
+                                 "Clinical pathway 2"))
+ 
+ # Setup matrixpls to estimate the same model. Note that ASGSCA places dependent
+ # variables on columns but matrixpls uses rows for dependent variables
+ 
+ inner <- t(B0)
+ formative <- t(W0)
+ reflective <- matrix(0,8,4)
+ 
+ colnames(formative) <- rownames(reflective) <- names(GenPhen)
+ 
+ colnames(inner) <- rownames(inner) <- 
+   rownames(formative) <- colnames(reflective) <-
+   c("Gene1","Gene2","Clinical pathway 1","Clinical pathway 2")
+ 
+ model <- list(inner = inner, 
+               reflective = reflective,
+               formative = formative)
+ 
+ # Estimate using alternating least squares
+ 
+ matrixpls.res1 <- matrixpls(cov(GenPhen),  model,
+                             outerEstim = outerEstim.gsca,
+                             innerEstim = innerEstim.gsca)
+ 
+ # Estimate using direct minimization of the estimation criterion
+ # Set the convergence criterion to be slightly stricter than normally
+ # to get indentical results
+ 
+ matrixpls.res2 <- matrixpls(cov(GenPhen),  model,
+                             weightFun = weightFun.optim,
+                             optimCrit = optimCrit.gsca,
+                             control = list(reltol = 1e-12))
+ 
+ # Compare the weights
+ 
+ do.call(cbind,lapply(list(ASGSCA =GSCA.res[["Weight"]],
+                           matrixpls_als = t(attr(matrixpls.res1,"W")),
+                           matrixpls_optim =t(attr(matrixpls.res2,"W"))),
+                      function(W) W[W!=0]))
+ 
+ 
+ # Check the criterion function values
+ 
+ optimCrit.gsca(matrixpls.res1)
+ optimCrit.gsca(matrixpls.res2)
+ 
+ }
Loading required package: ASGSCA
[1] 1.873244
> 
> 
> 
> cleanEx()

detaching ‘package:ASGSCA’

> nameEx("cei")
> ### * cei
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cei
> ### Title: Composite Equivalence Indices
> ### Aliases: cei
> 
> ### ** Examples
> 
> # Load the Tenenhaus et al 2005 model and data from semPLS
> library(semPLS)
Loading required package: lattice

Attaching package: ‘semPLS’

The following object is masked from ‘package:matrixpls’:

    gof

> data(ECSImobi)
> data(mobi)
> 
> # Reflective and empty formative model
> reflective<- ECSImobi$M
> formative <- t(reflective)
> formative[] <- 0
> 
> # Estimation using covariance matrix
> model <- list(inner =  t(ECSImobi$D),
+               reflective = reflective,
+               formative = formative)
> 
> 
> S <- cor(mobi)
> 
> matrixpls.ModeA <- matrixpls(S, model, innerEstim = innerEstim.centroid)
> matrixpls.Fixed <- matrixpls(S, model, weightFun = weightFun.fixed)
> 
> cei(matrixpls.ModeA)

 Composite equilevance indices

 CEI individual
       Image  Expectation      Quality        Value Satisfaction   Complaints 
   0.9974792    0.9989714    0.9988475    0.9990601    0.9994073    1.0000000 
     Loyalty 
   0.9317274 

 CEI total: 0.9317274
> cei(matrixpls.ModeA, matrixpls.Fixed)

 Composite equilevance indices

 CEI individual
       Image  Expectation      Quality        Value Satisfaction   Complaints 
   0.9974792    0.9989714    0.9988475    0.9990601    0.9994073    1.0000000 
     Loyalty 
   0.9317274 

 CEI total: 0.9317274
> 
> 
> 
> cleanEx()

detaching ‘package:semPLS’, ‘package:lattice’

> nameEx("estimator")
> ### * estimator
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: estimator
> ### Title: Parameter estimation of a model matrix
> ### Aliases: estimator estimator.ols estimator.tsls estimator.plscLoadings
> ###   estimator.efaLoadings estimator.cfaLoadings estimator.plsreg
> 
> ### ** Examples
> 
> # Run the education example from the book
> 
> # Sanchez, G. (2013) PLS Path Modeling with R
> # Trowchez Editions. Berkeley, 2013. 
> # http://www.gastonsanchez.com/PLS Path Modeling with R.pdf
> 
> education <- read.csv("http://www.gastonsanchez.com/education.csv")
> 
> Support <- c(0, 0, 0, 0, 0, 0)
> Advising <- c(0, 0, 0, 0, 0, 0)
> Tutoring <- c(0, 0, 0, 0, 0, 0)
> Value <- c(1, 1, 1, 0, 0, 0)
> # Omit two paths (compared to the model in the book) to achieve 
> # identification of the 2SLS analysis
> Satisfaction <- c(0, 0, 1, 1, 0, 0)
> Loyalty <- c(0, 0, 0, 0, 1, 0)
> 
> inner <- rbind(Support, Advising, Tutoring, Value, Satisfaction, Loyalty)
> 
> 
> reflective <- diag(6)[c(rep(1,4),
+                         rep(2,4),
+                         rep(3,4),
+                         rep(4,4),
+                         rep(5,3),
+                         rep(6,4)),]
> formative <- matrix(0, 6, 23)
> 
> colnames(inner) <- colnames(reflective) <- rownames(formative) <- rownames(inner)
> rownames(reflective) <- colnames(formative) <- colnames(education)[2:24]
> 
> education.model <- list(inner = inner,
+               reflective = reflective,
+               formative = formative)
> 
> # Reverse code two variables
> education[,c("sup.under","loy.asha")] <- - education[,c("sup.under","loy.asha")]
> 
> S <- cor(education[,2:24])
> 
> # PLSc with OLS regression
> 
> education.out <- matrixpls(S,education.model,
+                       disattenuate = TRUE,
+                       parametersReflective = estimator.plscLoadings)
> 
> # PLSc with 2SLS regresssion
> 
> education.out2 <- matrixpls(S,education.model,
+                       disattenuate = TRUE,
+                       parametersReflective = estimator.plscLoadings,
+                       parametersInner = estimator.tsls)
> 
> 
> # Disattenuated regression with unit-weighted scales and exploratory factor analysis
> # reliability estimates (with unconstrained MINRES estimator)
> 
> education.out3 <- matrixpls(S,education.model,
+                        disattenuate = TRUE,
+                        weightFun = weightFun.fixed,
+                        parametersReflective = estimator.efaLoadings)
> 
> # Disattenuated GSCA with 2SLS regression after disattenuated based on 
> # confirmatory factor analysis reliability estimates
> 
> 
> education.out4 <- matrixpls(S,education.model,
+                        disattenuate = TRUE,
+                        innerEstim = innerEstim.gsca,
+                        outerEstim = outerEstim.gsca,
+                        parametersInner = estimator.tsls,
+                        parametersReflective = estimator.cfaLoadings)
> 
> 
> # Compare the results
> 
> cbind(PLSc = education.out, PLSc_2sls = education.out2, 
+       DR = education.out3, GSCAc = education.out4)
                               PLSc    PLSc_2sls           DR        GSCAc
Value~Support           0.960010008  0.960010008  0.961052003  0.954715076
Value~Advising         -0.006290538 -0.006290538 -0.025942728  0.002209031
Value~Tutoring         -0.016991857 -0.016991857 -0.008505033 -0.012777269
Satisfaction~Tutoring   0.259814316  0.228164120  0.265345531  0.219381010
Satisfaction~Value      0.616184166  0.673983285  0.611781568  0.680307794
Loyalty~Satisfaction    0.893606408  0.830432211  0.893665143  0.821313131
Support=~sup.help       0.774869508  0.774869508  0.826770163  0.774813730
Support=~sup.under      0.478043587  0.478043587  0.518570739  0.506017440
Support=~sup.safe       0.616627744  0.616627744  0.649685017  0.614494827
Support=~sup.conc       0.721380131  0.721380131  0.609564085  0.702944306
Advising=~adv.comp      0.830753619  0.830753619  0.873025117  0.874308268
Advising=~adv.acces     0.820720021  0.820720021  0.784148545  0.783036066
Advising=~adv.comm      0.936497516  0.936497516  0.883381362  0.886793858
Advising=~adv.qual      0.908957821  0.908957821  0.958331347  0.956552079
Tutoring=~tut.prof      0.777789458  0.777789458  0.868491889  0.871142110
Tutoring=~tut.sched     0.811042518  0.811042518  0.777272336  0.769988789
Tutoring=~tut.stud      0.765328615  0.765328615  0.649445133  0.653695388
Tutoring=~tut.qual      0.729647485  0.729647485  0.795264570  0.797561469
Value=~val.devel        0.800133312  0.800133312  0.886331446  0.879637882
Value=~val.deci         0.816358971  0.816358971  0.864998912  0.873681825
Value=~val.meet         0.844734996  0.844734996  0.871683784  0.851191130
Value=~val.info         0.916210979  0.916210979  0.766435572  0.794581205
Satisfaction=~sat.glad  0.906805623  0.906805623  0.844373652  0.881930323
Satisfaction=~sat.expe  0.826930142  0.826930142  0.868287989  0.836696496
Satisfaction=~sat.over  0.871952833  0.871952833  0.894807922  0.883219197
Loyalty=~loy.proud      0.804977309  0.804977309  0.833899511  0.843341054
Loyalty=~loy.recom      0.847856524  0.847856524  0.917891697  0.894978950
Loyalty=~loy.asha       0.581138960  0.581138960  0.516364987  0.528040278
Loyalty=~loy.back       0.713757327  0.713757327  0.671290279  0.694500422
Support=+sup.help       0.392730089  0.392730089  0.332621369  0.390176075
Support=+sup.under      0.242288667  0.242288667  0.332621369  0.249238770
Support=+sup.safe       0.312527808  0.312527808  0.332621369  0.323003523
Support=+sup.conc       0.365619863  0.365619863  0.332621369  0.352326608
Advising=+adv.comp      0.261514617  0.261514617  0.275590349  0.278376481
Advising=+adv.acces     0.258356120  0.258356120  0.275590349  0.259794048
Advising=+adv.comm      0.294801953  0.294801953  0.275590349  0.277288676
Advising=+adv.qual      0.286132676  0.286132676  0.275590349  0.285619868
Tutoring=+tut.prof      0.302201030  0.302201030  0.299623241  0.310613456
Tutoring=+tut.sched     0.315121119  0.315121119  0.299623241  0.302975281
Tutoring=+tut.stud      0.297359515  0.297359515  0.299623241  0.276602359
Tutoring=+tut.qual      0.283496027  0.283496027  0.299623241  0.305783406
Value=+val.devel        0.267163554  0.267163554  0.281634044  0.265168835
Value=+val.deci         0.272581282  0.272581282  0.281634044  0.268466612
Value=+val.meet         0.282056002  0.282056002  0.281634044  0.243131832
Value=+val.info         0.305921748  0.305921748  0.281634044  0.352841771
Satisfaction=+sat.glad  0.380446923  0.380446923  0.364388192  0.421717327
Satisfaction=+sat.expe  0.346935462  0.346935462  0.364388192  0.308561006
Satisfaction=+sat.over  0.365824564  0.365824564  0.364388192  0.362455105
Loyalty=+loy.proud      0.334085495  0.334085495  0.310246371  0.331341697
Loyalty=+loy.recom      0.351881430  0.351881430  0.310246371  0.359035969
Loyalty=+loy.asha       0.241187043  0.241187043  0.310246371  0.240094481
Loyalty=+loy.back       0.296226946  0.296226946  0.310246371  0.291934295
> 
> # Compare the reliability estimates
> 
> cbind(PLSc = attr(education.out,"Q"), PLSc_2sls = attr(education.out2,"Q"), 
+       DR = attr(education.out3,"Q"), GSCAc = attr(education.out4,"Q"))
                  PLSc PLSc_2sls        DR     GSCAc
Support      0.7684334 0.7684334 0.7505490 0.7648953
Advising     0.9321055 0.9321055 0.9297960 0.9330075
Tutoring     0.8557273 0.8557273 0.8574349 0.8622437
Value        0.9117234 0.9117234 0.9112314 0.9122543
Satisfaction 0.9041434 0.9041434 0.9027491 0.9029266
Loyalty      0.8443286 0.8443286 0.8316575 0.8654427
> 
> 
> 
> cleanEx()
> nameEx("matrixpls.plspm")
> ### * matrixpls.plspm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: matrixpls.plspm
> ### Title: A plspm compatibility wrapper for matrixpls
> ### Aliases: matrixpls.plspm
> 
> ### ** Examples
> 
> cores <- getOption("mc.cores")
> options(mc.cores=2)
> 
> # Run the example from plspm package
> 
> # load dataset satisfaction
> data(satisfaction)
Warning in data(satisfaction) : data set ‘satisfaction’ not found
> # inner model matrix
> IMAG = c(0,0,0,0,0,0)
> EXPE = c(1,0,0,0,0,0)
> QUAL = c(0,1,0,0,0,0)
> VAL = c(0,1,1,0,0,0)
> SAT = c(1,1,1,1,0,0)
> LOY = c(1,0,0,0,1,0)
> sat_inner = rbind(IMAG, EXPE, QUAL, VAL, SAT, LOY)
> # outer model list
> sat_outer = list(1:5, 6:10, 11:15, 16:19, 20:23, 24:27)
> # vector of modes (reflective indicators)
> sat_mod = rep("A", 6)
> 
> # apply matrixpls
> matrixpls.res <- matrixpls.plspm(satisfaction, sat_inner, sat_outer, sat_mod,
+                                  scaled=FALSE, boot.val=FALSE)
Loading required namespace: boot
Loading required namespace: parallel
Error in get_params(x = Data, path_matrix, outer = blocks, modes = modes,  : 
  object 'satisfaction' not found
Calls: matrixpls.plspm -> get_params
Execution halted
